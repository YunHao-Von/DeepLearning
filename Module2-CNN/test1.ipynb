{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image  # 本包用来读取图片为数据矩阵\n",
    "from torch.utils.data import ConcatDataset,DataLoader,Subset\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfm = transforms.Compose([\n",
    "    transforms.Resize((128,128)),  # 将图像矩阵全部转化为128*128矩阵\n",
    "    transforms.ToTensor(),  # 将图像矩阵转化为张量进行存储\n",
    "])\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # 将图像矩阵全部转化为128*128矩阵\n",
    "    transforms.ToTensor(),  # 将图像矩阵转化为张量进行存储\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128  # 设定每个批次的图片数量\n",
    "train_set = DatasetFolder(\"Data/training\",loader=lambda x:Image.open(x),extensions='jpg',\n",
    "                          transform=train_tfm)  # DataFolder会自动根据文件夹生成数据集，同时指定transform确认数据转化函数\n",
    "valid_set = DatasetFolder(\"Data/validation\",loader=lambda x:Image.open(x),extensions='jpg',\n",
    "                          transform=test_tfm)  # DataFolder会自动根据文件夹生成数据集，同时指定transform确认数据转化函数\n",
    "test_set = DatasetFolder(\"Data/evaluation\", loader=lambda x: Image.open(x), extensions='jpg',\n",
    "                         transform=test_tfm)  # DataFolder会自动根据文件夹生成数据集，同时指定transform确认数据转化函数\n",
    "train_loader = DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=0,pin_memory=True)\n",
    "valid_loader = DataLoader(valid_set,batch_size=batch_size,shuffle=True,num_workers=0,pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier,self).__init__()\n",
    "        \"\"\"\n",
    "        输入参数:\n",
    "        torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        torch.nn.MaxPool2d(kernel_size,stride,padding)\n",
    "        input image size:[3,128,128]\n",
    "        \"\"\"\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(3,64,3,1,1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2,0),\n",
    "            \n",
    "            nn.Conv2d(64,128,3,1,1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2,0),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4, 4, 0)\n",
    "        )  # 可以用Sequential方法来将网络进行分层\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(256*8*8,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,11)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        input x:[batch_size,3,128,128]\n",
    "        output:[batch_size,11]\n",
    "        \"\"\"\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickletools import optimize\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # 探明计算机器\n",
    "model = Classifier().to(device)  # 初始化模型\n",
    "model.device = device\n",
    "criterion = nn.CrossEntropyLoss()  # 选用交叉熵函数作为损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0003,weight_decay=1e-5)  # 定义优化器\n",
    "n_epochs = 80\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # 让模型进入训练模式\n",
    "    train_loss = list()\n",
    "    train_accs = list()\n",
    "    for batch in tqdm(train_loader):\n",
    "        imgs,labels = batch\n",
    "        imgs = imgs.to(device)  # 数据和模型必须在一个device上\n",
    "        logits = model(imgs)  # 执行模型中的forward函数\n",
    "        loss = criterion(logits,labels.to(device))  # 计算本batch的损失\n",
    "        optimizer.zero_grad()  # 清空优化器中的梯度\n",
    "        loss.backward()  # 计算梯度\n",
    "        grad_norm = nn.utils.clip_grad_norm_(model.parameters(),max_norm=10)  # 修剪梯度\n",
    "        optimizer.step()  # 使用计算好的梯度更新模型\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()  # 计算准确度\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "    print(\"第\"+str(epoch)+\"轮的损失为\"+str(train_loss)+\",准确率为\"+str(train_acc))\n",
    "    \"\"\"进入验证模式\"\"\"\n",
    "    model.eval()  # 模型进入验证模式\n",
    "    valid_loss = list()\n",
    "    valid_accs = list()\n",
    "    for batch in tqdm(valid_loader):\n",
    "        imgs, labels = batch\n",
    "        imgs = imgs.to(device)  # 数据和模型必须在一个device上\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs)  # 执行模型中的forward函数\n",
    "        loss = criterion(logits, labels.to(device))  # 计算本batch的损失\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)\n",
    "               ).float().mean()  # 计算准确度\n",
    "        valid_loss.append(loss.item())\n",
    "        valid_accs.append(acc)\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "    print(\"第\"+str(epoch)+\"轮的验证损失为\"+str(valid_loss)+\",验证准确率为\"+str(valid_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Models/model.pth')  # 保存当前模型在指定路径下\n",
    "\"\"\"测试模型\"\"\"\n",
    "model.eval()\n",
    "predictions = list()\n",
    "for batch in tqdm(test_loader):\n",
    "    imgs,labels = batch\n",
    "    with torch.no_grad():\n",
    "        logits = model(imgs.to(device))  # 执行模型中的forward函数\n",
    "    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n",
    "with open('predict.csv','w') as f:\n",
    "    f.write(\"ID,Category\\n\")\n",
    "    for i,pred in enumerate(predictions):\n",
    "        f.write(f\"{i},{pred}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d12a6980af1de3549060b7b451d48d445ec6b4aaeaf0b0e12a509d2182e95745"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
