# 对抗攻击(adversarial_attack)   
要将训练好的神经网络应用于工业界，必须保证神经网络模型的稳健性。而要保证模型的稳健性，则模型应该可以应对来自人类的恶意攻击。  
## 一、恶意攻击
+ 举例:图像中加入小型杂序数据，小到人类肉眼无法识别，加入后送入模型影响模型分类结果。  

分类:    
+ Non-targeted:只要模型输出标签不是正确的标签即可。  
+ Targeted:要模型输出指定的错误标签。  

### 1.1 Non-targeted 攻击  
